Legal LLM Evaluation Report
==================================================

Benchmark: benchmarks/intellectual_property_humaneval.jsonl
Total samples: 2
Models evaluated: mock-legal

Model Performance Summary:
------------------------------

mock-legal:
  Strategy: role_based
    pass@1: 1.000
    avg_citation_accuracy: 0.500
    avg_reasoning_coherence: 0.300
    avg_completeness: 0.500
    avg_hallucination_rate: 0.000

Comparative Analysis:
--------------------
Best pass@1: mock-legal (1.000)

Efficiency Metrics:
mock-legal:
  Avg response time: 0.50s
  Avg tokens: 212
  Error rate: 0.0%
